Wed Aug 30 14:35:38 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-PCIE-32GB            Off| 00000000:58:00.0 Off |                    0 |
| N/A   30C    P0               26W / 250W|      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE-32GB            Off| 00000000:D8:00.0 Off |                    0 |
| N/A   27C    P0               24W / 250W|      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
0

HOSTNAME = e00161
Running on 14 processor(s) on 1 node(s).
Running  GPUs.
Wed Aug 30 14:35:38 CEST 2023


EnvironmentNameNotFound: Could not find conda environment: gpu
You can list all discoverable environments with `conda info --envs`.


Device : cuda
loading data as batch
Total number of samples in the train dataset: 17
Number of batches: 9
Total number of samples in the validation dataset: 8
Number of batches: 4
Total number of samples in the test dataset: 10
Number of batches: 5
Data path: /home/tappay01/data/data1/Data1_1250MeV_75Mm_-71.5Mm.npy
Data path: /home/tappay01/data/data1/Data1_1250MeV_75Mm_-46.5Mm.npy
Processing train batch 0
Training Critic
Traceback (most recent call last):
  File "main.py", line 114, in <module>
    step_fake 
  File "/home/tappay01/program/engine.py", line 83, in train_step
    loss_critic.backward(retain_graph=True) # able to reuse
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py", line 175, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 31.74 GiB total capacity; 29.51 GiB already allocated; 935.12 MiB free; 29.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Total time elapsed: 00h00m17s (on  cores)
Done.
