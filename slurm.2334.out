Sun Sep  3 19:18:12 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-PCIE-32GB            Off| 00000000:58:00.0 Off |                    0 |
| N/A   29C    P0               26W / 250W|      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE-32GB            Off| 00000000:D8:00.0 Off |                    0 |
| N/A   27C    P0               24W / 250W|      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
0

HOSTNAME = e00161
Running on 14 processor(s) on 1 node(s).
Running  GPUs.
Sun Sep  3 19:18:13 CEST 2023


EnvironmentNameNotFound: Could not find conda environment: gpu
You can list all discoverable environments with `conda info --envs`.


  0%|          | 0/3 [00:00<?, ?it/s]
Device : cuda
loading data as batch
Total number of samples in the train dataset: 21
Number of batches: 3
Total number of samples in the validation dataset: 7
Number of batches: 1
Total number of samples in the test dataset: 7
Number of batches: 1
[INFO] training the network...
Processing train batch 0
Traceback (most recent call last):
  File "main.py", line 111, in <module>
    step_fake 
  File "/home/tappay01/program/engine.py", line 72, in train_step
    fake = gen(cond)  
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tappay01/program/model.py", line 170, in forward
    decFeatures = self.decoder(b, encFeatures[::-1][0:])
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tappay01/program/model.py", line 109, in forward
    x = self.dec_blocks[i](x)
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tappay01/program/model.py", line 56, in forward
    return self.conv2(self.relu(self.conv1(x)))
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/nn/modules/activation.py", line 98, in forward
    return F.relu(input, inplace=self.inplace)
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py", line 1457, in relu
    result = torch.relu(input)
RuntimeError: CUDA out of memory. Tried to allocate 4.00 GiB (GPU 0; 31.74 GiB total capacity; 30.42 GiB already allocated; 57.12 MiB free; 30.43 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Total time elapsed: 00h00m17s (on  cores)
Done.
