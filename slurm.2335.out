Sun Sep  3 19:19:03 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  Tesla V100-PCIE-32GB            Off| 00000000:58:00.0 Off |                    0 |
| N/A   30C    P0               26W / 250W|      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  Tesla V100-PCIE-32GB            Off| 00000000:D8:00.0 Off |                    0 |
| N/A   26C    P0               24W / 250W|      0MiB / 32768MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
0

HOSTNAME = e00161
Running on 14 processor(s) on 1 node(s).
Running  GPUs.
Sun Sep  3 19:19:03 CEST 2023


EnvironmentNameNotFound: Could not find conda environment: gpu
You can list all discoverable environments with `conda info --envs`.


  0%|          | 0/3 [00:00<?, ?it/s]
Device : cuda
loading data as batch
Total number of samples in the train dataset: 21
Number of batches: 6
Total number of samples in the validation dataset: 7
Number of batches: 2
Total number of samples in the test dataset: 7
Number of batches: 2
[INFO] training the network...
Processing train batch 0
Traceback (most recent call last):
  File "main.py", line 111, in <module>
    step_fake 
  File "/home/tappay01/program/engine.py", line 76, in train_step
    gp = gradient_penalty(critic, real, fake, cond, device=device)
  File "/home/tappay01/program/model.py", line 208, in gradient_penalty
    only_inputs=True)[0] # get first element
  File "/home/tappay01/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py", line 278, in grad
    allow_unused, accumulate_grad=False)  # Calls into the C++ engine to run the backward pass
RuntimeError: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 31.74 GiB total capacity; 30.11 GiB already allocated; 319.12 MiB free; 30.13 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF


Total time elapsed: 00h00m14s (on  cores)
Done.
